#R group porject
# Install and load the required package
install.packages("ISLR")
library(ISLR)

# Load the Default dataset
data("Default")

# 1.1 Split the data into training and testing sets
set.seed(123)  # Set a seed for reproducibility
sample_index <- sample(1:nrow(Default), size = 0.75 * nrow(Default))
train_data <- Default[sample_index, ]
test_data <- Default[-sample_index, ]

# 1.2 Build a Logistic Regression model
model <- glm(default ~ ., data = train_data, family = binomial)

# 1.3 Evaluate the model using the test data
# 1.3.1 Build a confusion matrix
predicted_probs <- predict(model, newdata = test_data, type = "response")
predicted_classes <- ifelse(predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test_data$default, predicted_classes)
print(confusion_matrix)

# 1.3.2 Calculate true positive, true negative, false positive, and false negative
tp <- confusion_matrix[2, 2]  # True positive
tn <- confusion_matrix[1, 1]  # True negative
fp <- confusion_matrix[1, 2]  # False positive
fn <- confusion_matrix[2, 1]  # False negative
print(paste("True Positive:", tp))
print(paste("True Negative:", tn))
print(paste("False Positive:", fp))
print(paste("False Negative:", fn))

# 1.3.3 Calculate accuracy, precision, recall, and misclassification rate
accuracy <- (tp + tn) / sum(confusion_matrix)
precision <- tp / (tp + fp)
recall <- tp / (tp + fn)
misclassification_rate <- 1 - accuracy
print(paste("Accuracy:", accuracy))
print(paste("Precision:", precision))
print(paste("Recall:", recall))
print(paste("Misclassification Rate:", misclassification_rate))

# 1.4 Class Imbalance
# The response variable 'default' is imbalanced, with 'No' being the majority class and 'Yes' being the minority class.
# This imbalance can affect the model's performance, especially for the minority class.

# 1.5 Model Summary Report
# Model: Logistic Regression
# Dataset: Default
# Split: 75% training, 25% testing
#
# Evaluation Metrics:
# - Accuracy: [accuracy value]
# - Precision: [precision value]
# - Recall: [recall value]
# - Misclassification Rate: [misclassification rate]
#
# Confusion Matrix:
#        Predicted
# Actual  No  Yes
#   No    [tn]  [fp]
#   Yes   [fn]  [tp]
